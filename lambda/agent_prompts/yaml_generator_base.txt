Generate GitHub Actions workflow YAML based on this pipeline design: {pipeline_design}.

REPOSITORY STRUCTURE CONTEXT:
{repo_structure}

CRITICAL: TERRAFORM WORKING DIRECTORY:
- Terraform files are located in: {terraform_working_dir}
- When running terraform commands (init, plan, apply), you MUST change to this directory first using `working-directory: {terraform_working_dir}` or `cd {terraform_working_dir}`
- Example CORRECT format:
  - name: Terraform Init
    working-directory: {terraform_working_dir}
    run: terraform init
- If terraform_working_dir is ".", Terraform files are in the repository root
- If terraform_working_dir is a subdirectory (e.g., "infrastructure"), you MUST specify the working-directory in ALL terraform steps

WORKFLOW TRIGGERS (CRITICAL):
- The workflow MUST trigger ONLY when a pull request is closed (merged) to the main branch
- Use ONLY the `pull_request` trigger with `types: [closed]` and `branches: [main]`
- Example CORRECT format:
  on:
    pull_request:
      branches:
        - main
      types:
        - closed
- This ensures the workflow runs only when PRs are merged (closed) to main, not on PR open/update

Requirements:
- Use aws-actions/configure-aws-credentials@v4 for AWS authentication via OIDC (OpenID Connect)
- Configure AWS credentials using role-to-assume: ${{{{ secrets.AWS_ROLE_TO_ASSUME }}}} and aws-region: ${{{{ vars.AWS_REGION }}}}
- DO NOT use AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY - use OIDC authentication only
- Include security scanning and validation stages
- Reference secrets via secrets.* and variables via vars.*

CRITICAL: NPM SETUP (IF NPM IS USED):
- IF npm commands MUST be included for some reason, you MUST NOT include the `cache` parameter at all
- NEVER use `cache: 'npm'` - it requires a lock file (package-lock.json) and will cause workflow failures with "Dependencies lock file is not found"
- DO NOT include any cache parameter when using actions/setup-node@v6
- ALL npm commands MUST include `|| true` to prevent workflow failures - this ensures the workflow continues even if npm commands fail
- Example CORRECT format (if npm setup is required):
  - uses: actions/setup-node@v6
    with:
      node-version: 24
      # DO NOT include cache parameter
  - name: Install dependencies
    run: npm ci || true
  - name: Run lint
    run: npm run lint || true
- Example INCORRECT format (DO NOT USE):
  - uses: actions/setup-node@v6
    with:
      node-version: 24
      cache: 'npm'  # ❌ WRONG - will fail if lock file doesn't exist
  - run: npm ci  # ❌ WRONG - will fail the workflow if npm ci fails
- Simply omit the cache parameter entirely - do not set it to any value
- ALWAYS append `|| true` to ALL npm commands (npm ci, npm install, npm run, npm test, etc.) to ensure workflow continues even on failure

CRITICAL: OIDC PERMISSIONS REQUIREMENT (MUST INCLUDE):
- When using aws-actions/configure-aws-credentials@v4 with OIDC, you MUST set permissions at the job level
- The `id-token: write` permission is REQUIRED for OIDC authentication - without it, the workflow will fail with "Could not load credentials"
- The `contents: read` permission is typically required for checkout and other operations
- Example CORRECT format (add permissions to EVERY job that uses AWS credentials):
  jobs:
    my-job:
      runs-on: ubuntu-latest
      permissions:
        id-token: write  # REQUIRED for OIDC
        contents: read    # Required for checkout and file operations
      steps:
        - uses: actions/checkout@v3
        - name: Configure AWS Credentials
          uses: aws-actions/configure-aws-credentials@v4
          with:
            role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
            aws-region: ${{ vars.AWS_REGION }}
- EVERY job that uses aws-actions/configure-aws-credentials@v4 MUST have these permissions
- If a job uses AWS credentials, it MUST have `id-token: write` permission or OIDC will fail

QUALITY AND SECURITY SCANNING REQUIREMENTS (MANDATORY - PARALLEL JOBS):
All quality and security scans must be split into SEPARATE PARALLEL JOBS that run simultaneously. This improves pipeline speed and allows independent execution of each scan type.

CRITICAL: Create separate parallel jobs for each scan type. DO NOT combine them into a single "quality" job.

Required parallel jobs (all run in parallel, no dependencies between them):

1. SAST Job (Static Application Security Testing) - Use Semgrep:
   - Job name: `sast` or `sast-scan`
   - Tool: Semgrep
   - Example job structure:
     sast:
       runs-on: ubuntu-latest
       permissions:
         contents: read
       steps:
         - uses: actions/checkout@v3
         - name: Install Semgrep
           run: pip install semgrep
         - name: Run Semgrep SAST
           continue-on-error: true
           run: semgrep --config auto . || true

2. SCA Job (Software Composition Analysis) - Use Trivy:
   - Job name: `sca` or `sca-scan`
   - Tool: Trivy filesystem scanner
   - Example job structure:
     sca:
       runs-on: ubuntu-latest
       permissions:
         contents: read
       steps:
         - uses: actions/checkout@v3
         - name: Install Trivy
           run: curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.47.0
         - name: Trivy SCA (Filesystem)
           continue-on-error: true
           run: trivy fs --scanners vuln . || true

3. Secrets Scanning Job - Use Trivy:
   - Job name: `secrets-scan` or `secrets`
   - Tool: Trivy secrets scanner
   - Example job structure:
     secrets-scan:
       runs-on: ubuntu-latest
       permissions:
         contents: read
       steps:
         - uses: actions/checkout@v3
         - name: Install Trivy
           run: curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.47.0
         - name: Trivy Secrets Scan
           continue-on-error: true
           run: trivy fs --scanners secret . || true

4. IaC Security Scanning Job - Use Trivy AND Checkov:
   - Job name: `iac-scan` or `iac-security`
   - Tools: Trivy config scanner AND Checkov
   - Example job structure:
     iac-scan:
       runs-on: ubuntu-latest
       permissions:
         contents: read
       steps:
         - uses: actions/checkout@v3
         - name: Install Trivy
           run: curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.47.0
         - name: Install Checkov
           run: pip install checkov
         - name: Trivy IaC Scan
           continue-on-error: true
           run: trivy config . || true
         - name: Run Checkov
           continue-on-error: true
           run: checkov -d . || true

CRITICAL REQUIREMENTS:
- All quality/security jobs MUST run in PARALLEL (no `needs:` dependencies between them)
- Each job MUST include `continue-on-error: true` OR append `|| true` to commands
- Security scans are informational and should never block the pipeline
- All jobs require `permissions: contents: read` for checkout
- Infrastructure job should depend on ALL quality jobs: `needs: [sast, sca, secrets-scan, iac-scan]`

CRITICAL JOB SEQUENCING RULES:
- Quality/security jobs (sast, sca, secrets-scan, iac-scan) run in PARALLEL with no dependencies between them
- If Terraform creates ECR resources, infrastructure job MUST run BEFORE container build job
- Use job dependencies (needs:) to enforce proper sequencing
- Infrastructure job should depend on ALL quality/security jobs: `needs: [sast, sca, secrets-scan, iac-scan]`
- Container build job should depend on infrastructure job when ECR is in Terraform
- Example correct sequencing:
  jobs:
    sast:
      runs-on: ubuntu-latest
      # No needs: - runs in parallel
    sca:
      runs-on: ubuntu-latest
      # No needs: - runs in parallel
    secrets-scan:
      runs-on: ubuntu-latest
      # No needs: - runs in parallel
    iac-scan:
      runs-on: ubuntu-latest
      # No needs: - runs in parallel
    infrastructure:
      needs: [sast, sca, secrets-scan, iac-scan]  # Waits for all quality jobs
      runs-on: ubuntu-latest

TERRAFORM SETUP REQUIREMENTS:
- ALWAYS setup Terraform CLI (hashicorp/setup-terraform@v3) BEFORE any terraform commands
- Use cli_config_credentials_token: ${{{{ secrets.TF_API_TOKEN }}}} if Terraform Cloud/Enterprise is used
- Setup step must come before terraform init, plan, or apply
- CRITICAL: All terraform commands (init, plan, apply, output) MUST run in the correct working directory
- Use `working-directory: {terraform_working_dir}` in each terraform step, OR use `cd {terraform_working_dir} && terraform ...` format

CRITICAL: TERRAFORM OUTPUT ROOT CAUSE ANALYSIS AND PREVENTION:
- Terraform output commands fail for these COMMON REASONS:
  1. **Terraform apply failed or was skipped** - Most common cause! Check if terraform apply step succeeded
  2. **Output names don't match** - Output name in workflow doesn't match terraform code (e.g., "ecr_registry" vs "ecr_registry_url")
  3. **Outputs not defined** - Outputs don't exist in terraform .tf files
  4. **Terraform state issues** - State not initialized, corrupted, or locked
  5. **Wrong working directory** - Running terraform output in wrong directory

PREVENTION (MUST DO BEFORE GETTING OUTPUTS):
- ALWAYS verify terraform apply succeeded: Check step outcome with `steps.terraform-apply.outcome == 'success'`
- ALWAYS use output names discovered from codebase analysis: The static analyzer has already extracted actual output names from .tf files
- NEVER hardcode output names: Output names vary by codebase (e.g., "ecs_cluster" vs "ecs_cluster_name", "ecr_repository_url" vs separate "ecr_registry" and "ecr_repository")
- The codebase analysis provides the actual output names - use those exact names in your workflow
- ALWAYS check terraform state is initialized: Ensure terraform init ran successfully

CRITICAL: USE DISCOVERED OUTPUT NAMES FROM CODEBASE ANALYSIS:
- The static analyzer has already analyzed the terraform codebase and discovered the actual output names
- Use the output names provided in the guidance sections (ecr_guidance, ecs_guidance)
- These names are extracted directly from the terraform .tf files, so they are guaranteed to match
- DO NOT try to discover names at runtime - use the names from codebase analysis
- If discovered names are empty, it means outputs weren't found in the codebase - use GitHub variables as fallback

ERROR HANDLING:
- If terraform output fails, environment variables will contain error messages like "::error::Terraform exited with code 1."
- This causes docker build and other commands to fail with cryptic errors
- ALWAYS include error handling when extracting terraform outputs:
  - Verify terraform apply succeeded BEFORE trying to get outputs
  - List available outputs for debugging
  - Capture stderr with `2>&1` to see actual error messages
  - Check if output contains "Error" or is empty
  - Provide fallback to GitHub variables if terraform output fails
  - Validate values before using them

Example CORRECT format using discovered output names from codebase analysis:
  - name: Get ECR Details
    id: ecr-details
    working-directory: {terraform_working_dir}
    run: |
      # Use output names discovered from codebase analysis (provided in ecr_guidance section)
      # Example: If analysis found "ecr_repository_url", use that exact name
      REPO_URL=$(terraform output -raw ecr_repository_url 2>&1)
      if [[ "$REPO_URL" == *"Error"* ]] || [[ -z "$REPO_URL" ]]; then
        echo "Warning: Failed to get ecr_repository_url, using GitHub variables"
        REGISTRY="${{{{ vars.ECR_REGISTRY }}}}"
        REPOSITORY="${{{{ vars.ECR_REPOSITORY }}}}"
      else
        # Parse repository URL
        REGISTRY=$(echo "$REPO_URL" | sed 's|/.*||')
        REPOSITORY=$(echo "$REPO_URL" | sed 's|.*/||')
      fi
      echo "registry=$REGISTRY" >> $GITHUB_OUTPUT
      echo "repository=$REPOSITORY" >> $GITHUB_OUTPUT
- Example INCORRECT format (DO NOT USE - hardcodes output names without using discovered names):
  - name: Get ECR Details
    id: ecr-details
    working-directory: {terraform_working_dir}
    run: |
      # ❌ WRONG: Hardcodes output names without checking what was discovered from codebase analysis
      echo "registry=$(terraform output -raw ecr_registry)" >> $GITHUB_OUTPUT
      echo "repository=$(terraform output -raw ecr_repository)" >> $GITHUB_OUTPUT
  # This will fail if outputs are named differently (e.g., "ecr_repository_url" instead)
  # ✅ CORRECT: Use the output names provided in the ecr_guidance section from codebase analysis

Example CORRECT terraform workflow (with root cause prevention):
  - name: Setup Terraform
    uses: hashicorp/setup-terraform@v3
    with:
      cli_config_credentials_token: ${{{{ secrets.TF_API_TOKEN }}}}
  - name: Terraform Init
    working-directory: {terraform_working_dir}
    run: terraform init
  - name: Terraform Plan
    working-directory: {terraform_working_dir}
    run: terraform plan
  - name: Terraform Apply
    id: terraform-apply
    working-directory: {terraform_working_dir}
    run: terraform apply -auto-approve
  - name: Verify Apply Succeeded
    working-directory: {terraform_working_dir}
    run: |
      if [ "${{{{ steps.terraform-apply.outcome }}}}" != "success" ]; then
        echo "Error: Terraform apply failed. Cannot proceed."
        exit 1
      fi
  - name: List Outputs (Debug)
    working-directory: {terraform_working_dir}
    continue-on-error: true
    run: terraform output
  - name: Get Terraform Outputs
    id: terraform-outputs
    working-directory: {terraform_working_dir}
    run: |
      # Verify apply succeeded
      if [ "${{{{ steps.terraform-apply.outcome }}}}" != "success" ]; then
        echo "Error: Cannot get outputs - terraform apply failed"
        exit 1
      fi
      # Use output name discovered from codebase analysis (provided in ecr_guidance section)
      # Example: If analysis found "ecr_repository_url", use that exact name
      REGISTRY=$(terraform output -raw ecr_repository_url 2>&1)
      if [[ "$REGISTRY" == *"Error"* ]] || [[ -z "$REGISTRY" ]]; then
        echo "Error: Failed to get discovered output name"
        terraform output
        exit 1
      fi
      echo "registry=$REGISTRY" >> $GITHUB_OUTPUT

CRITICAL: AWS CLI COMMAND FORMATTING:
- ALL AWS CLI commands MUST be written on a SINGLE LINE
- DO NOT split AWS CLI commands across multiple lines
- Use single-line format even if the command is long
- Example CORRECT format:
  run: aws ecs update-service --cluster ${{ env.ECS_CLUSTER }} --service ${{ env.ECS_SERVICE }} --force-new-deployment
- Example CORRECT format (with YAML literal block for multiple commands):
  run: |
    aws ecs update-service --cluster ${{ env.ECS_CLUSTER }} --service ${{ env.ECS_SERVICE }} --force-new-deployment
    aws ecs wait services-stable --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }}
- Example INCORRECT format (DO NOT USE):
  run: |
    aws ecs update-service 
      --cluster ${{ env.ECS_CLUSTER }} 
      --service ${{ env.ECS_SERVICE }}
- This rule applies to ALL AWS CLI commands: aws ecs, aws ecr, aws sts, aws s3, etc.
- Other commands (terraform, docker, etc.) can use multi-line format if needed, but AWS CLI must always be single-line

CRITICAL: DOCKER BUILD ERROR PREVENTION:
- Before running docker build/push, ALWAYS validate that ECR_REGISTRY and ECR_REPOSITORY are set correctly
- If these environment variables contain error messages (like "::error::Terraform exited with code 1."), docker commands will fail
- Add validation step before docker build:
  - name: Validate ECR Values
    run: |
      if [[ -z "$ECR_REGISTRY" ]] || [[ "$ECR_REGISTRY" == *"Error"* ]] || [[ "$ECR_REGISTRY" == *"error"* ]]; then
        echo "Error: ECR_REGISTRY is invalid: $ECR_REGISTRY"
        exit 1
      fi
      if [[ -z "$ECR_REPOSITORY" ]] || [[ "$ECR_REPOSITORY" == *"Error"* ]] || [[ "$ECR_REPOSITORY" == *"error"* ]]; then
        echo "Error: ECR_REPOSITORY is invalid: $ECR_REPOSITORY"
        exit 1
      fi
      echo "ECR_REGISTRY=$ECR_REGISTRY"
      echo "ECR_REPOSITORY=$ECR_REPOSITORY"

ECR Configuration Handling:
{ecr_guidance}

ECS Configuration Handling:
{ecs_guidance}

Add concise comments and a README-style explanation after the YAML.

Return ONLY the workflow inside a ```yaml code fence followed immediately by the README text. Do not include any other prose before the YAML block.

